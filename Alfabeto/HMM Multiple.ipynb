{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import alfabeto_data.dissertation_images as di\n",
    "import alfabeto_data.hmm_threading as ht\n",
    "from alfabeto_data.harmonic_function_data import ordered_numeral_list\n",
    "from alfabeto_sources.all_sources import *\n",
    "from alfabeto_sources import *\n",
    "from alfabeto_code.AlfabetoConverter import transposed_pc_chords_noMMD\n",
    "from Continuo.ContinuoConverter import figure_intervals_pc\n",
    "import csv, copy, time\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import write_dot, to_agraph\n",
    "from scipy.spatial.distance import euclidean, cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def many_hmm(corpus_dict, mode, n_functions, crd_type):\n",
    "    total_estemit = []\n",
    "    corpus_names = []\n",
    "    all_numerals = ['I', 'i', 'bII', 'bii', 'II', 'ii', 'bIII', 'biii', 'III', 'iii', 'IV', 'iv',\n",
    "                    '#IV', '#iv', 'V', 'v', 'bVI', 'bvi', 'VI', 'vi', 'bVII', 'bvii', 'VII', 'vii']\n",
    "    all_numerals = ordered_numeral_list\n",
    "    for j, x in corpus_dict.items():\n",
    "        temp_emit = []\n",
    "        corpus_names.append(j)\n",
    "        X = '_'\n",
    "        if type(x) is tuple:\n",
    "            X = di.python_hmm_corpus(x, mode)\n",
    "        elif type(x) is list:\n",
    "            X = di.python_hmm(x, mode, crd_type)\n",
    "        K = n_functions\n",
    "        Y = hmm.MultinomialHMM(n_components=K, verbose=False,n_iter=500,tol=.001)\n",
    "        Y.n_features=len(X[2])\n",
    "        a = Y.fit(X[0], X[1])\n",
    "        ESTTR11 = a.transmat_\n",
    "        TOKEN_NAMES=X[2]\n",
    "        ESTEMIT11 = a.emissionprob_\n",
    "        \n",
    "        #trying to insert unused numerals...\n",
    "        ordered_emit = [] #T-S-D\n",
    "        numerals_in = [] #indices of numerals in the corpus\n",
    "        numerals_not = [] #indices of numerals not in the corpus\n",
    "        for numeral in all_numerals:\n",
    "            if numeral in TOKEN_NAMES:\n",
    "                numerals_in.append(all_numerals.index(numeral))\n",
    "            else:\n",
    "                numerals_not.append(all_numerals.index(numeral))\n",
    "        for n_nu in numerals_not:\n",
    "            ESTEMIT11 = np.insert(ESTEMIT11, n_nu, np.array([0 for numb in range(K)]), 1)\n",
    "        \n",
    "        \n",
    "        for r in range(len(all_numerals)):\n",
    "            if all_numerals[r] == 'I':\n",
    "                row = ESTEMIT11[:,r]\n",
    "                most = max(row)\n",
    "                for f in range(len(row)):\n",
    "                    if row[f] == most:\n",
    "                        temp_emit.append(ESTEMIT11[f])\n",
    "            if all_numerals[r] == 'IV':\n",
    "                row = ESTEMIT11[:,r]\n",
    "                most = max(row)\n",
    "                for f in range(len(row)):\n",
    "                    if row[f] == most:\n",
    "                        temp_emit.append(ESTEMIT11[f])\n",
    "            if all_numerals[r] == 'V':\n",
    "                row = ESTEMIT11[:,r]\n",
    "                most = max(row)\n",
    "                for f in range(len(row)):\n",
    "                    if row[f] == most:\n",
    "                        temp_emit.append(ESTEMIT11[f])\n",
    "        temp_emit_2 = []\n",
    "        for xx in temp_emit:\n",
    "            for yy in xx:\n",
    "                temp_emit_2.append(yy)\n",
    "        \n",
    "        total_estemit.append(temp_emit_2)\n",
    "\n",
    "\n",
    "#         print(len(total_estemit[0]))\n",
    "        print('done one')\n",
    "    return total_estemit, corpus_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for corpus in ['alfabeto_continuo', 'bach', 'palestrina']:\n",
    "    for mode in ['major', 'minor']:\n",
    "        for mc_type in range(5):\n",
    "            flipped_data = {}\n",
    "#             corpus = 'alfabeto_continuo'\n",
    "            K_range = 5\n",
    "#             mode = 'major'\n",
    "            KK = [2, 3, 4, 5, 6, 8, 9, 12]\n",
    "            for K in range(2, K_range+1):\n",
    "            # for K in KK:\n",
    "                all_data = []\n",
    "                all_labels = []\n",
    "                l_number = joblib.load('/home/daniel/Desktop/hmm_mc/%s/%s/%s/%s/0.pkl' % (corpus, mode, K, mc_type))['test'][0]\n",
    "                print(len(l_number))\n",
    "                l_numeral = joblib.load('/home/daniel/Desktop/hmm_mc/%s/%s/%s/%s/0.pkl' % (corpus, mode, K, mc_type))['train'][2]\n",
    "                for l in l_number:\n",
    "                    if l[0] < len(l_numeral):\n",
    "                        all_labels.append(l_numeral[l[0]])\n",
    "                    else:\n",
    "                        all_labels.append('o')\n",
    "            #             print('one didn\\'t fit...')\n",
    "                for x in range(500):\n",
    "                    temp_data = []  \n",
    "                    c = joblib.load('/home/daniel/Desktop/hmm_mc/%s/%s/%s/%s/%s.pkl' % (corpus, mode, K, mc_type, x))['decode']\n",
    "            #         print('decoded')\n",
    "                    for xx in c[1]:\n",
    "                        temp_data.append(xx)        \n",
    "                    all_data.append(temp_data)\n",
    "#                 for x in np.array(all_data):\n",
    "#                     print(len(x))\n",
    "                numpied = np.swapaxes(np.array(all_data), 0, 1)\n",
    "            #     print(numpied.shape)\n",
    "                DIST = []\n",
    "                st = time.time()\n",
    "                DIST = cdist(numpied, numpied, 'hamming')\n",
    "            #     DIST = (cdist(numpied, numpied, 'hamming')*len(l_number))**2 #Quinn/White\n",
    "            #     print('DIST', K, time.time()-st)\n",
    "            #     flipped_data.append(DIST)\n",
    "                st2 = time.time()\n",
    "                flipped_data[K] = di.k_means_simple(DIST, K, all_labels)\n",
    "            #     print_labels = ['$'+x+'$' for x in all_labels]\n",
    "            #     di.k_means_data(DIST, K, print_labels, '/home/daniel/Desktop/hmmkmeans/%s_%s.pdf' % (corpus, K))\n",
    "            #     print('kmeans took', time.time()-st2)\n",
    "                print(corpus, mode, K, mc_type, '-->', flipped_data[K])\n",
    "            all_data.append({(corpus, mode, mc_type): flipped_data})\n",
    "joblib.dump(all_data, '/home/daniel/Desktop/silhouette_data.pkl', compress=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in range(2, 5):\n",
    "    for mc in range(5):\n",
    "        xlen = []\n",
    "        for x in range(50):\n",
    "            xx = joblib.load('hmm2/hmm_mc/alfabeto_continuo/major/%s/%s/%s.pkl' % (k, mc, x))\n",
    "            xlen.append(len(xx['decode'][1]))\n",
    "        if len(set(xlen))>1:\n",
    "            print('yikes!', k, mc)\n",
    "            print(xlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "from sklearn.externals import joblib\n",
    "rc = ipp.Client()\n",
    "dview = rc[:]\n",
    "\n",
    "dview.execute('import numpy as np')\n",
    "dview.execute('import time')\n",
    "dview.execute('from sklearn.externals import joblib')\n",
    "dview.execute('from scipy.spatial.distance import cdist')\n",
    "dview.execute('import alfabeto_data.dissertation_images as di')\n",
    "\n",
    "\n",
    "@dview.parallel(block=True)\n",
    "def silhouette_hmm(mc):\n",
    "    corpus_name = 'alfabeto_continuo'\n",
    "    mode_name = 'major'\n",
    "    K_range = 15\n",
    "    flipped_data = {}\n",
    "    for K in range(2, K_range+1):\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        l_number = joblib.load('hmm2/hmm_mc/%s/%s/%s/%s/0.pkl' % (corpus_name, mode_name, K, mc))['test'][0]\n",
    "        l_numeral = joblib.load('hmm2/hmm_mc/%s/%s/%s/%s/0.pkl' % (corpus_name, mode_name, K, mc))['train'][2]\n",
    "        for l in l_number:\n",
    "            if l[0] < len(l_numeral):\n",
    "                all_labels.append(l_numeral[l[0]])\n",
    "            else:\n",
    "                all_labels.append('o')\n",
    "        #             print('one didn\\'t fit...')\n",
    "        for x in range(50):\n",
    "            temp_data = []\n",
    "            print(x)\n",
    "            c = joblib.load('hmm2/hmm_mc/%s/%s/%s/%s/%s.pkl' % (corpus_name, mode_name, K, mc, x))['decode']\n",
    "    #         print('decoded')\n",
    "            for xx in c[1]:\n",
    "                temp_data.append(xx)\n",
    "            all_data.append(temp_data)\n",
    "        numpied = np.swapaxes(np.array(all_data), 0, 1)\n",
    "    #     print(numpied.shape)\n",
    "        st = time.time()\n",
    "        DIST = cdist(numpied, numpied, 'hamming')\n",
    "    #     DIST = (cdist(numpied, numpied, 'hamming')*len(l_number))**2 #Quinn/White\n",
    "        st2 = time.time()\n",
    "        flipped_data[K] = di.k_means_simple(DIST, K, all_labels)\n",
    "    #     print_labels = ['$'+x+'$' for x in all_labels]\n",
    "    #     di.k_means_data(DIST, K, print_labels, '/home/daniel/Desktop/hmmkmeans/%s_%s.pdf' % (corpus, K))\n",
    "    #     print('kmeans took', time.time()-st2)\n",
    "        print(K, '-->', flipped_data[K])\n",
    "    return flipped_data\n",
    "\n",
    "j = silhouette_hmm.map([mc for mc in range(5)])\n",
    "joblib.dump(j, 'silhouette_alfabeto_data.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "badones = []\n",
    "for corpus in ['alfabeto_continuo', 'bach', 'palestrina']:\n",
    "    for mode in ['major', 'minor']:\n",
    "        for K in range(2, 15):\n",
    "            for mc_type in range(5):\n",
    "                for krange in range(500):\n",
    "                    try:\n",
    "#                         print('fine')\n",
    "                        x = joblib.load('/home/daniel/Desktop/hmm_mc/%s/%s/%s/%s/%s.pkl' % (corpus, mode, K, mc_type, krange))\n",
    "                    except EOFError:\n",
    "                        badones.append((corpus, mode, K, mc_type, krange))\n",
    "                        print((corpus, mode, K, mc_type, krange))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(badones, '/home/daniel/Desktop/badones.pkl')\n",
    "import os\n",
    "for x in badones:\n",
    "    os.remove('/home/daniel/Desktop/hmm_mc/%s/%s/%s/%s/%s.pkl' % (x[0], x[1], x[2], x[3], x[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
