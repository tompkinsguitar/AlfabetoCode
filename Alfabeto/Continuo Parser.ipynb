{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this imports the necessary modules\n",
    "from music21 import *\n",
    "import pickle, time, os\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A is the path to the folder that holds all of the songs\n",
    "# A = 'kern_files/wtc/'\n",
    "A = corpus.getComposer('monteverdi') #ignore this for now\n",
    "\n",
    "\n",
    "#these match the key or mode of the song with the appropriate label\n",
    "tonal_major_dict = {(0, 0): 'CM', (1, 7): 'GM', (2, 2): 'DM', (3, 9): 'AM', (4, 4): 'EM', (5, 11): 'BM', (6, 6): 'F♯M',\n",
    "               (-1, 5): 'FM', (-2, 10): 'B♭M', (-3, 3): 'E♭M', (-4, 8): 'A♭M', (-5, 1): 'D♭M', (-6, 6): 'G♭M'}\n",
    "tonal_minor_dict = {(0, 9): 'am', (1, 4): 'em', (2, 11): 'bm', (3, 6): 'f♯m', (4, 1): 'c♯m', (5, 8): 'g♯m',\n",
    "                    (6, 3): 'd♯m', (-1, 2): 'dm', (-2, 7): 'gm', (-3, 0): 'cm', (-4, 5): 'fm', (-5, 10): 'b♭m',\n",
    "                    (-6, 3): 'e♭m'}\n",
    "modal_major = [('f', 5), ('n', 0), ('f', 0), ('n', 7), ('f', 10), ('n', 5),\n",
    "               (-1, 5), (0, 0), (-1, 0), (0, 7), (-1, 10), (0, 5)]\n",
    "modal_minor = [('n', 2), ('n', 9), ('f', 2), ('f', 7), ('n', 4),\n",
    "               (0, 2), (0, 9), (-1, 2), (-1, 7), (0, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function converts .krn or .xml files into the format we need\n",
    "def data_converter(unparsed, modality, corpus_name):\n",
    "    pitch_frequency_data = []\n",
    "    all_parsed = []\n",
    "    all_keys = []\n",
    "    all_chords = []\n",
    "\n",
    "    def parser(parsed_songs):\n",
    "        for x in all_parsed:\n",
    "            if type(x) is stream.Score:\n",
    "    #             print('we have a score!')\n",
    "                song_chords = []\n",
    "                crd = x.chordify().flat.getElementsByClass(chord.Chord)\n",
    "                if len(x.flat.getElementsByClass(key.KeySignature)) > 0:\n",
    "                    key_sig = x.flat.getElementsByClass(key.KeySignature)[0].sharps\n",
    "                    bass_note = crd[-1].bass().pitchClass\n",
    "                    modal_type = []\n",
    "                    if modality == 'tonal':\n",
    "                        for c in tonal_major_dict.keys():\n",
    "                            modal_type.append(c)\n",
    "                        for c in tonal_minor_dict.keys():\n",
    "                            modal_type.append(c)\n",
    "                            #                 modal_type.append(c for c in tonal_minor_dict.keys())\n",
    "                    elif modality == 'modal':\n",
    "                        for c in modal_major:\n",
    "                            modal_type.append(c)\n",
    "                        for c in modal_minor:\n",
    "                            modal_type.append(c)\n",
    "                            #             print(modal_type, (key_sig, bass_note))\n",
    "                    if (key_sig, bass_note) in modal_type:\n",
    "                        print((key_sig, bass_note), 'is in there')\n",
    "                        for c in crd:\n",
    "                            song_chord = []\n",
    "                            note_bass = (c.bass().pitchClass - bass_note) % 12\n",
    "                            song_chord.append(note_bass)\n",
    "                            song_chord.append(sorted(set([(n.pitchClass - bass_note - note_bass) % 12 for n in c])))\n",
    "                            song_chords.append(song_chord)\n",
    "                        all_chords.append(song_chords)\n",
    "                        all_keys.append((key_sig, bass_note))\n",
    "                    # this is for pitch class frequency data\n",
    "                        all_notes = []\n",
    "                        note_data = {}\n",
    "                        song_percents = []\n",
    "                        note_counter = 0\n",
    "                        for xx in crd:\n",
    "                            for yy in xx:\n",
    "                                all_notes.append((yy.pitchClass - bass_note) % 12)\n",
    "                                note_counter += 1\n",
    "                        for xx in range(12):\n",
    "                            note_data[xx] = 0\n",
    "                        for xx in all_notes:\n",
    "                            note_data[xx] += 1\n",
    "                        for xx in range(12):\n",
    "                            song_percents.append(note_data[xx] / len(all_notes) * 100)\n",
    "                        pitch_frequency_data.append(song_percents)\n",
    "                        print(len(pitch_frequency_data), len(all_keys))\n",
    "                        print((key_sig, bass_note))\n",
    "                    #                 all_corpus_labels.append((the_key[0].sharps, bass_note))\n",
    "\n",
    "            elif type(x) is stream.Opus:\n",
    "                print('we have an Opus!')\n",
    "                for y in x:\n",
    "                    song_chords = []\n",
    "                    crd = y.chordify().flat.getElementsByClass(chord.Chord)\n",
    "                    if len(x.flat.getElementsByClass(key.KeySignature)) > 0:\n",
    "                        key_sig = y.flat.getElementsByClass(key.KeySignature)[0].sharps\n",
    "                        bass_note = crd[-1].bass().pitchClass\n",
    "                        modal_type = []\n",
    "                        if modality == 'tonal':\n",
    "                            for c in tonal_major_dict.keys():\n",
    "                                modal_type.append(c)\n",
    "                            for c in tonal_minor_dict.keys():\n",
    "                                modal_type.append(c)\n",
    "                                #                     modal_type.append(c for c in tonal_minor_dict.keys())\n",
    "                        elif modality == 'modal':\n",
    "                            for c in modal_major:\n",
    "                                modal_type.append(c)\n",
    "                            for c in modal_minor:\n",
    "                                modal_type.append(c)\n",
    "                        if (key_sig, bass_note) in modal_type:\n",
    "                            print((key_sig, bass_note), 'is in there')\n",
    "                            for c in crd:\n",
    "                                song_chord = []\n",
    "                                note_bass = (c.bass().pitchClass - bass_note) % 12\n",
    "                                song_chord.append(note_bass)\n",
    "                                song_chord.append(sorted(set([(n.pitchClass - bass_note - note_bass) % 12 for n in c])))\n",
    "                                song_chords.append(song_chord)\n",
    "                            all_chords.append(song_chords)\n",
    "                            all_keys.append((key_sig, bass_note))\n",
    "                        # this is for pitch class frequency data\n",
    "                            all_notes = []\n",
    "                            note_data = {}\n",
    "                            song_percents = []\n",
    "                            note_counter = 0\n",
    "                            for xx in crd:\n",
    "                                for yy in xx:\n",
    "                                    all_notes.append((yy.pitchClass - bass_note) % 12)\n",
    "                                    note_counter += 1\n",
    "                            for xx in range(12):\n",
    "                                note_data[xx] = 0\n",
    "                            for xx in all_notes:\n",
    "                                note_data[xx] += 1\n",
    "                            for xx in range(12):\n",
    "                                song_percents.append(note_data[xx] / len(all_notes) * 100)\n",
    "                            pitch_frequency_data.append(song_percents)\n",
    "                            print(len(pitch_frequency_data), len(all_keys))\n",
    "\n",
    "    start = time.time()\n",
    "    if type(unparsed) is str:\n",
    "\n",
    "        for root, dirs, files in os.walk(unparsed):\n",
    "            for file_name, x in zip(files, range(len(files))):\n",
    "#                 print(file_name, '...', x + 1, 'of', len(files)+1, '...')\n",
    "                if file_name.endswith('.krn'):\n",
    "                    #                     print('it is a krn')\n",
    "                    path = os.path.join(root, file_name)\n",
    "                    st = time.time()\n",
    "                    print('parsing', file_name)\n",
    "                    all_parsed.append(converter.parse(path))\n",
    "#                     parser(path)\n",
    "                    fin = time.time()\n",
    "                    print('parsed', len(all_parsed), 'of', len(unparsed), 'in', fin - st, 'seconds')\n",
    "    else:\n",
    "        for x in unparsed:\n",
    "            st = time.time()\n",
    "#             print('parsing', x)\n",
    "            all_parsed.append(converter.parse(x))\n",
    "#             parser(x)\n",
    "            fin = time.time()\n",
    "            print('parsed', len(all_parsed), 'of', len(unparsed), 'in', fin - st, 'seconds')\n",
    "    print('entire process took:', time.time() - start, 'seconds')\n",
    "    parser(all_parsed)\n",
    "    joblib.dump((all_chords, all_keys), 'pickles/%s_continuo.pkl' % corpus_name, compress=9)\n",
    "    joblib.dump((pitch_frequency_data, all_keys), 'pickles/%s_notes.pkl' % corpus_name, compress=9)\n",
    "\n",
    "    print('ALL DONE!!! :) :) :)')\n",
    "    \n",
    "def chordify_maker(unparsed, modality, corpus_name):\n",
    "    all_chords = []\n",
    "\n",
    "    def parser(parsed_songs):\n",
    "        for x in all_parsed:\n",
    "            if type(x) is stream.Score:\n",
    "    #             print('we have a score!')\n",
    "                song_chords = []\n",
    "                crd = x.chordify().flat.getElementsByClass(chord.Chord)\n",
    "                if len(x.flat.getElementsByClass(key.KeySignature)) > 0:\n",
    "                    key_sig = x.flat.getElementsByClass(key.KeySignature)[0].sharps\n",
    "                    bass_note = crd[-1].bass().pitchClass\n",
    "                    modal_type = []\n",
    "                    if modality == 'tonal':\n",
    "                        for c in tonal_major_dict.keys():\n",
    "                            modal_type.append(c)\n",
    "                        for c in tonal_minor_dict.keys():\n",
    "                            modal_type.append(c)\n",
    "                            #                 modal_type.append(c for c in tonal_minor_dict.keys())\n",
    "                    elif modality == 'modal':\n",
    "                        for c in modal_major:\n",
    "                            modal_type.append(c)\n",
    "                        for c in modal_minor:\n",
    "                            modal_type.append(c)\n",
    "                            #             print(modal_type, (key_sig, bass_note))\n",
    "                    if (key_sig, bass_note) in modal_type:\n",
    "                        print((key_sig, bass_note), 'is in there')\n",
    "                        for c in crd:\n",
    "                            song_chord = []\n",
    "                            note_bass = (c.bass().pitchClass - bass_note) % 12\n",
    "                            song_chord.append(note_bass)\n",
    "                            song_chord.append(sorted(set([(n.pitchClass - bass_note - note_bass) % 12 for n in c])))\n",
    "                            song_chords.append(song_chord)\n",
    "                        all_chords.append(song_chords)\n",
    "                        all_keys.append((key_sig, bass_note))\n",
    "                    # this is for pitch class frequency data\n",
    "                        all_notes = []\n",
    "                        note_data = {}\n",
    "                        song_percents = []\n",
    "                        note_counter = 0\n",
    "                        for xx in crd:\n",
    "                            for yy in xx:\n",
    "                                all_notes.append((yy.pitchClass - bass_note) % 12)\n",
    "                                note_counter += 1\n",
    "                        for xx in range(12):\n",
    "                            note_data[xx] = 0\n",
    "                        for xx in all_notes:\n",
    "                            note_data[xx] += 1\n",
    "                        for xx in range(12):\n",
    "                            song_percents.append(note_data[xx] / len(all_notes) * 100)\n",
    "                        pitch_frequency_data.append(song_percents)\n",
    "                        print(len(pitch_frequency_data), len(all_keys))\n",
    "                        print((key_sig, bass_note))\n",
    "                    #                 all_corpus_labels.append((the_key[0].sharps, bass_note))\n",
    "\n",
    "            elif type(x) is stream.Opus:\n",
    "                print('we have an Opus!')\n",
    "                for y in x:\n",
    "                    song_chords = []\n",
    "                    crd = y.chordify().flat.getElementsByClass(chord.Chord)\n",
    "                    if len(x.flat.getElementsByClass(key.KeySignature)) > 0:\n",
    "                        key_sig = y.flat.getElementsByClass(key.KeySignature)[0].sharps\n",
    "                        bass_note = crd[-1].bass().pitchClass\n",
    "                        modal_type = []\n",
    "                        if modality == 'tonal':\n",
    "                            for c in tonal_major_dict.keys():\n",
    "                                modal_type.append(c)\n",
    "                            for c in tonal_minor_dict.keys():\n",
    "                                modal_type.append(c)\n",
    "                                #                     modal_type.append(c for c in tonal_minor_dict.keys())\n",
    "                        elif modality == 'modal':\n",
    "                            for c in modal_major:\n",
    "                                modal_type.append(c)\n",
    "                            for c in modal_minor:\n",
    "                                modal_type.append(c)\n",
    "                        if (key_sig, bass_note) in modal_type:\n",
    "                            print((key_sig, bass_note), 'is in there')\n",
    "                            for c in crd:\n",
    "                                song_chord = []\n",
    "                                note_bass = (c.bass().pitchClass - bass_note) % 12\n",
    "                                song_chord.append(note_bass)\n",
    "                                song_chord.append(sorted(set([(n.pitchClass - bass_note - note_bass) % 12 for n in c])))\n",
    "                                song_chords.append(song_chord)\n",
    "                            all_chords.append(song_chords)\n",
    "                            all_keys.append((key_sig, bass_note))\n",
    "                        # this is for pitch class frequency data\n",
    "                            all_notes = []\n",
    "                            note_data = {}\n",
    "                            song_percents = []\n",
    "                            note_counter = 0\n",
    "                            for xx in crd:\n",
    "                                for yy in xx:\n",
    "                                    all_notes.append((yy.pitchClass - bass_note) % 12)\n",
    "                                    note_counter += 1\n",
    "                            for xx in range(12):\n",
    "                                note_data[xx] = 0\n",
    "                            for xx in all_notes:\n",
    "                                note_data[xx] += 1\n",
    "                            for xx in range(12):\n",
    "                                song_percents.append(note_data[xx] / len(all_notes) * 100)\n",
    "                            pitch_frequency_data.append(song_percents)\n",
    "                            print(len(pitch_frequency_data), len(all_keys))\n",
    "\n",
    "    start = time.time()\n",
    "    if type(unparsed) is str:\n",
    "\n",
    "        for root, dirs, files in os.walk(unparsed):\n",
    "            for file_name, x in zip(files, range(len(files))):\n",
    "#                 print(file_name, '...', x + 1, 'of', len(files)+1, '...')\n",
    "                if file_name.endswith('.krn'):\n",
    "                    #                     print('it is a krn')\n",
    "                    path = os.path.join(root, file_name)\n",
    "                    st = time.time()\n",
    "                    print('parsing', file_name)\n",
    "                    all_parsed.append(converter.parse(path))\n",
    "#                     parser(path)\n",
    "                    fin = time.time()\n",
    "                    print('parsed', len(all_parsed), 'of', len(unparsed), 'in', fin - st, 'seconds')\n",
    "    else:\n",
    "        for x in unparsed:\n",
    "            st = time.time()\n",
    "#             print('parsing', x)\n",
    "            all_parsed.append(converter.parse(x))\n",
    "#             parser(x)\n",
    "            fin = time.time()\n",
    "            print('parsed', len(all_parsed), 'of', len(unparsed), 'in', fin - st, 'seconds')\n",
    "    print('entire process took:', time.time() - start, 'seconds')\n",
    "    parser(all_parsed)\n",
    "    joblib.dump((all_chords, all_keys), 'pickles/%s_continuo.pkl' % corpus_name, compress=9)\n",
    "    joblib.dump((pitch_frequency_data, all_keys), 'pickles/%s_notes.pkl' % corpus_name, compress=9)\n",
    "\n",
    "    print('ALL DONE!!! :) :) :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed 1 of 97 in 1.488415002822876 seconds\n",
      "parsed 2 of 97 in 11.710393190383911 seconds\n",
      "parsed 3 of 97 in 1.2722439765930176 seconds\n",
      "parsed 4 of 97 in 6.344343900680542 seconds\n",
      "parsed 5 of 97 in 1.4849927425384521 seconds\n",
      "parsed 6 of 97 in 7.557887077331543 seconds\n",
      "parsed 7 of 97 in 2.0217461585998535 seconds\n",
      "parsed 8 of 97 in 13.627753973007202 seconds\n",
      "parsed 9 of 97 in 1.763542890548706 seconds\n",
      "parsed 10 of 97 in 7.690062999725342 seconds\n",
      "parsed 11 of 97 in 1.1763591766357422 seconds\n",
      "parsed 12 of 97 in 7.4613940715789795 seconds\n",
      "parsed 13 of 97 in 0.7616748809814453 seconds\n",
      "parsed 14 of 97 in 4.444546937942505 seconds\n",
      "parsed 15 of 97 in 1.2413420677185059 seconds\n",
      "parsed 16 of 97 in 9.273782014846802 seconds\n",
      "parsed 17 of 97 in 2.5262868404388428 seconds\n",
      "parsed 18 of 97 in 5.139539003372192 seconds\n",
      "parsed 19 of 97 in 1.3440728187561035 seconds\n",
      "parsed 20 of 97 in 10.959871053695679 seconds\n",
      "parsed 21 of 97 in 1.5114281177520752 seconds\n",
      "parsed 22 of 97 in 12.72885513305664 seconds\n",
      "parsed 23 of 97 in 3.873645067214966 seconds\n",
      "parsed 24 of 97 in 6.123311996459961 seconds\n",
      "parsed 25 of 97 in 9.966081142425537 seconds\n",
      "parsed 26 of 97 in 2.0611321926116943 seconds\n",
      "parsed 27 of 97 in 19.07620906829834 seconds\n",
      "parsed 28 of 97 in 4.431787967681885 seconds\n",
      "parsed 29 of 97 in 22.754492044448853 seconds\n",
      "parsed 30 of 97 in 6.052208185195923 seconds\n",
      "parsed 31 of 97 in 17.07537579536438 seconds\n",
      "parsed 32 of 97 in 5.679606199264526 seconds\n",
      "parsed 33 of 97 in 21.64166283607483 seconds\n",
      "parsed 34 of 97 in 3.1095659732818604 seconds\n",
      "parsed 35 of 97 in 22.23906397819519 seconds\n",
      "parsed 36 of 97 in 4.415052890777588 seconds\n",
      "parsed 37 of 97 in 21.41627788543701 seconds\n",
      "parsed 38 of 97 in 1.0691018104553223 seconds\n",
      "parsed 39 of 97 in 7.662527084350586 seconds\n",
      "parsed 40 of 97 in 1.0969960689544678 seconds\n",
      "parsed 41 of 97 in 7.860774278640747 seconds\n",
      "parsed 42 of 97 in 5.024816036224365 seconds\n",
      "parsed 43 of 97 in 11.57840633392334 seconds\n",
      "parsed 44 of 97 in 3.64090895652771 seconds\n",
      "parsed 45 of 97 in 16.05542016029358 seconds\n",
      "parsed 46 of 97 in 6.185800075531006 seconds\n",
      "parsed 47 of 97 in 10.685264110565186 seconds\n",
      "parsed 48 of 97 in 2.8622629642486572 seconds\n",
      "parsed 49 of 97 in 15.264513731002808 seconds\n",
      "parsed 50 of 97 in 2.3639230728149414 seconds\n",
      "parsed 51 of 97 in 17.77027201652527 seconds\n",
      "parsed 52 of 97 in 1.8435430526733398 seconds\n",
      "parsed 53 of 97 in 10.347633838653564 seconds\n",
      "parsed 54 of 97 in 1.8784701824188232 seconds\n",
      "parsed 55 of 97 in 8.094624996185303 seconds\n",
      "parsed 56 of 97 in 4.7423858642578125 seconds\n",
      "parsed 57 of 97 in 26.505768060684204 seconds\n",
      "parsed 58 of 97 in 1.7355358600616455 seconds\n",
      "parsed 59 of 97 in 10.963845014572144 seconds\n",
      "parsed 60 of 97 in 1.7346444129943848 seconds\n",
      "parsed 61 of 97 in 11.140279054641724 seconds\n",
      "parsed 62 of 97 in 1.4391920566558838 seconds\n",
      "parsed 63 of 97 in 18.275344848632812 seconds\n",
      "parsed 64 of 97 in 1.915658950805664 seconds\n",
      "parsed 65 of 97 in 10.86837100982666 seconds\n",
      "parsed 66 of 97 in 2.9998929500579834 seconds\n",
      "parsed 67 of 97 in 16.94042205810547 seconds\n",
      "parsed 68 of 97 in 1.6523172855377197 seconds\n",
      "parsed 69 of 97 in 21.804697036743164 seconds\n",
      "parsed 70 of 97 in 4.3321168422698975 seconds\n",
      "parsed 71 of 97 in 14.1628258228302 seconds\n",
      "parsed 72 of 97 in 4.973800897598267 seconds\n",
      "parsed 73 of 97 in 23.14859914779663 seconds\n",
      "parsed 74 of 97 in 4.521760940551758 seconds\n",
      "parsed 75 of 97 in 13.730509042739868 seconds\n",
      "parsed 76 of 97 in 1.8052852153778076 seconds\n",
      "parsed 77 of 97 in 14.357241868972778 seconds\n",
      "parsed 78 of 97 in 3.1247458457946777 seconds\n"
     ]
    }
   ],
   "source": [
    "#crd_data(path_to_folder, mode, corpus_name)\n",
    "#for mode: If songs composed before 1700, use 'modal', otherwise, use 'tonal'. \n",
    "#for corpus_name: name it something simple that is similar to the name of the folder.\n",
    "\n",
    "data_converter(A, 'modal', 'monteverdi')\n",
    "\n",
    "#this will print out 'finished 1 of 20...'. It's possible to see \"finished 56 out of 20\". This is normal; some files\n",
    "    #contain more than one song. \n",
    "\n",
    "#nothing will be saved until this is finished. It should print \"ALL DONE!\" at the very end unless something went wrong.\n",
    "#it may take hours, so these are best run overnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do it in parallel\n",
    "import ipyparallel as ipp\n",
    "\n",
    "\n",
    "rc = ipp.Client()\n",
    "dview = rc[:]\n",
    "print(dview)\n",
    "\n",
    "dview.execute('from music21 import *')\n",
    "dview.execute('import pickle, time, os')\n",
    "dview.execute(\"from sklearn.externals import joblib\")\n",
    "\n",
    "@dview.parallel(block=True)\n",
    "def parallel_data_converter(number):\n",
    "    corpus_dict = {0: {'name': 'Zma', 'path': 'kern_files/Zma/', 'modality': 'modal'}, \n",
    "                   1: {'name': 'wtc', 'path': 'kern_files/wtc/', 'modality': 'tonal'}}\n",
    "    tonal_major_dict = {(0, 0): 'CM', (1, 7): 'GM', (2, 2): 'DM', (3, 9): 'AM', (4, 4): 'EM', (5, 11): 'BM', (6, 6): 'F♯M',\n",
    "               (-1, 5): 'FM', (-2, 10): 'B♭M', (-3, 3): 'E♭M', (-4, 8): 'A♭M', (-5, 1): 'D♭M', (-6, 6): 'G♭M'}\n",
    "    tonal_minor_dict = {(0, 9): 'am', (1, 4): 'em', (2, 11): 'bm', (3, 6): 'f♯m', (4, 1): 'c♯m', (5, 8): 'g♯m',\n",
    "                        (6, 3): 'd♯m', (-1, 2): 'dm', (-2, 7): 'gm', (-3, 0): 'cm', (-4, 5): 'fm', (-5, 10): 'b♭m',\n",
    "                        (-6, 3): 'e♭m'}\n",
    "    modal_major = [('f', 5), ('n', 0), ('f', 0), ('n', 7), ('f', 10), ('n', 5),\n",
    "                   (-1, 5), (0, 0), (-1, 0), (0, 7), (-1, 10), (0, 5)]\n",
    "    modal_minor = [('n', 2), ('n', 9), ('f', 2), ('f', 7), ('n', 4),\n",
    "                   (0, 2), (0, 9), (-1, 2), (-1, 7), (0, 4)]\n",
    "    # this function converts .krn or .xml files into the format we need\n",
    "    def data_converter(unparsed, modality, corpus_name):\n",
    "        pitch_frequency_data = []\n",
    "        all_parsed = []\n",
    "        all_keys = []\n",
    "        all_chords = []\n",
    "\n",
    "        def parser(parsed_songs):\n",
    "            for x in all_parsed:\n",
    "                if type(x) is stream.Score:\n",
    "        #             print('we have a score!')\n",
    "                    song_chords = []\n",
    "                    crd = x.chordify().flat.getElementsByClass(chord.Chord)\n",
    "                    if len(x.flat.getElementsByClass(key.KeySignature)) > 0:\n",
    "                        key_sig = x.flat.getElementsByClass(key.KeySignature)[0].sharps\n",
    "                        bass_note = crd[-1].bass().pitchClass\n",
    "                        modal_type = []\n",
    "                        if modality == 'tonal':\n",
    "                            for c in tonal_major_dict.keys():\n",
    "                                modal_type.append(c)\n",
    "                            for c in tonal_minor_dict.keys():\n",
    "                                modal_type.append(c)\n",
    "                                #                 modal_type.append(c for c in tonal_minor_dict.keys())\n",
    "                        elif modality == 'modal':\n",
    "                            for c in modal_major:\n",
    "                                modal_type.append(c)\n",
    "                            for c in modal_minor:\n",
    "                                modal_type.append(c)\n",
    "                                #             print(modal_type, (key_sig, bass_note))\n",
    "                        if (key_sig, bass_note) in modal_type:\n",
    "                            print((key_sig, bass_note), 'is in there')\n",
    "                            for c in crd:\n",
    "                                song_chord = []\n",
    "                                note_bass = (c.bass().pitchClass - bass_note) % 12\n",
    "                                song_chord.append(note_bass)\n",
    "                                song_chord.append(sorted(set([(n.pitchClass - bass_note - note_bass) % 12 for n in c])))\n",
    "                                song_chords.append(song_chord)\n",
    "                            all_chords.append(song_chords)\n",
    "                            all_keys.append((key_sig, bass_note))\n",
    "                        # this is for pitch class frequency data\n",
    "                            all_notes = []\n",
    "                            note_data = {}\n",
    "                            song_percents = []\n",
    "                            note_counter = 0\n",
    "                            for xx in crd:\n",
    "                                for yy in xx:\n",
    "                                    all_notes.append((yy.pitchClass - bass_note) % 12)\n",
    "                                    note_counter += 1\n",
    "                            for xx in range(12):\n",
    "                                note_data[xx] = 0\n",
    "                            for xx in all_notes:\n",
    "                                note_data[xx] += 1\n",
    "                            for xx in range(12):\n",
    "                                song_percents.append(note_data[xx] / len(all_notes) * 100)\n",
    "                            pitch_frequency_data.append(song_percents)\n",
    "                            print(len(pitch_frequency_data), len(all_keys))\n",
    "                            print((key_sig, bass_note))\n",
    "                        #                 all_corpus_labels.append((the_key[0].sharps, bass_note))\n",
    "\n",
    "                elif type(x) is stream.Opus:\n",
    "                    print('we have an Opus!')\n",
    "                    for y in x:\n",
    "                        song_chords = []\n",
    "                        crd = y.chordify().flat.getElementsByClass(chord.Chord)\n",
    "                        if len(x.flat.getElementsByClass(key.KeySignature)) > 0:\n",
    "                            key_sig = y.flat.getElementsByClass(key.KeySignature)[0].sharps\n",
    "                            bass_note = crd[-1].bass().pitchClass\n",
    "                            modal_type = []\n",
    "                            if modality == 'tonal':\n",
    "                                for c in tonal_major_dict.keys():\n",
    "                                    modal_type.append(c)\n",
    "                                for c in tonal_minor_dict.keys():\n",
    "                                    modal_type.append(c)\n",
    "                                    #                     modal_type.append(c for c in tonal_minor_dict.keys())\n",
    "                            elif modality == 'modal':\n",
    "                                for c in modal_major:\n",
    "                                    modal_type.append(c)\n",
    "                                for c in modal_minor:\n",
    "                                    modal_type.append(c)\n",
    "                            if (key_sig, bass_note) in modal_type:\n",
    "                                print((key_sig, bass_note), 'is in there')\n",
    "                                for c in crd:\n",
    "                                    song_chord = []\n",
    "                                    note_bass = (c.bass().pitchClass - bass_note) % 12\n",
    "                                    song_chord.append(note_bass)\n",
    "                                    song_chord.append(sorted(set([(n.pitchClass - bass_note - note_bass) % 12 for n in c])))\n",
    "                                    song_chords.append(song_chord)\n",
    "                                all_chords.append(song_chords)\n",
    "                                all_keys.append((key_sig, bass_note))\n",
    "                            # this is for pitch class frequency data\n",
    "                                all_notes = []\n",
    "                                note_data = {}\n",
    "                                song_percents = []\n",
    "                                note_counter = 0\n",
    "                                for xx in crd:\n",
    "                                    for yy in xx:\n",
    "                                        all_notes.append((yy.pitchClass - bass_note) % 12)\n",
    "                                        note_counter += 1\n",
    "                                for xx in range(12):\n",
    "                                    note_data[xx] = 0\n",
    "                                for xx in all_notes:\n",
    "                                    note_data[xx] += 1\n",
    "                                for xx in range(12):\n",
    "                                    song_percents.append(note_data[xx] / len(all_notes) * 100)\n",
    "                                pitch_frequency_data.append(song_percents)\n",
    "                                print(len(pitch_frequency_data), len(all_keys))\n",
    "\n",
    "        start = time.time()\n",
    "        if type(unparsed) is str:\n",
    "\n",
    "            for root, dirs, files in os.walk(unparsed):\n",
    "                for file_name, x in zip(files, range(len(files))):\n",
    "    #                 print(file_name, '...', x + 1, 'of', len(files)+1, '...')\n",
    "                    if file_name.endswith('.krn'):\n",
    "                        #                     print('it is a krn')\n",
    "                        path = os.path.join(root, file_name)\n",
    "                        st = time.time()\n",
    "                        all_parsed.append(converter.parse(path))\n",
    "    #                     parser(path)\n",
    "                        fin = time.time()\n",
    "    #                     print('finished', len(all_chords), 'of', len(unparsed), 'in', fin - st, 'seconds')\n",
    "        else:\n",
    "            for x in unparsed:\n",
    "                st = time.time()\n",
    "                parsed.append(converter.parse(x))\n",
    "    #             parser(x)\n",
    "                fin = time.time()\n",
    "    #             print('finished', len(all_chords), 'of', len(unparsed), 'in', fin - st, 'seconds')\n",
    "        print('entire process took:', time.time() - start, 'seconds')\n",
    "        parser(all_parsed)\n",
    "        joblib.dump((all_chords, all_keys), 'pickles/%s_continuo.pkl' % corpus_name, compress=9)\n",
    "        joblib.dump((pitch_frequency_data, all_keys), 'pickles/%s_notes.pkl' % corpus_name, compress=9)\n",
    "\n",
    "        print('ALL DONE!!! :) :) :)')\n",
    "    \n",
    "    data_converter(corpus_dict[number]['path'], corpus_dict[number]['modality'], corpus_dict[number]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_data_converter.map(range(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
