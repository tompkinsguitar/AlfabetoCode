{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import alfabeto_data.dissertation_images as di\n",
    "from alfabeto_sources.all_sources import *\n",
    "from alfabeto_code.AlfabetoConverter import transposed_pc_chords_noMMD\n",
    "from Continuo.ContinuoConverter import figure_intervals_pc\n",
    "import csv, copy, os\n",
    "from scipy.spatial.distance import euclidean, cdist\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import write_dot, to_agraph\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X = di.python_hmm(di.GetAll.all_alf, di.modal_major, 'chords')\n",
    "def function_graph_maker(corpus_function, corpus_name, mode, K_range, path):\n",
    "    X = corpus_function\n",
    "    for K in K_range:\n",
    "        if not os.path.exists('%s/%s_%s_%s.pkl' % (path, corpus_name, mode, K)):\n",
    "            Y = hmm.MultinomialHMM(n_components=K, verbose=True,n_iter=1000,tol=.001)\n",
    "            Y.n_features=len(X[2])\n",
    "            FIT_DATA = Y.fit(X[0], X[1])\n",
    "            TOKEN_NAMES=X[2]\n",
    "            pickleit = {'fit': FIT_DATA, 'tokens': TOKEN_NAMES}\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            joblib.dump(pickleit, '%s/%s_%s_%s.pkl' %(path, corpus_name, mode, K), compress=9)\n",
    "        \n",
    "        FIT_DATA = joblib.load('%s/%s_%s_%s.pkl' %(path, corpus_name, mode, K))\n",
    "        emiss = FIT_DATA['fit'].emissionprob_\n",
    "        tokens = FIT_DATA['tokens']\n",
    "        trans = FIT_DATA['fit'].transmat_\n",
    "\n",
    "        def pie_nodes(fit_data_dict):\n",
    "            emiss = fit_data_dict['fit'].emissionprob_\n",
    "            tokens = fit_data_dict['tokens']\n",
    "        #     K = len(emiss)\n",
    "            plt.close()\n",
    "            for k in range(K):\n",
    "                plt.figure(figsize=(2,2), tight_layout=True)\n",
    "                emit1_data = []\n",
    "                emit1_labels = []\n",
    "                plt.rcParams['font.size'] = 14.0\n",
    "                plt.rcParams['font.family'] = 'serif'\n",
    "                plt.axis('equal')\n",
    "                # csfont = {'fontname':'Comic Sans MS'}\n",
    "                kcolors = ['white']\n",
    "                other_numb = 0\n",
    "                for a, b in zip(emiss[k], tokens):\n",
    "                    if a >= .03:\n",
    "                        emit1_data.append(a)\n",
    "                        emit1_labels.append(b)\n",
    "                    else:\n",
    "                        other_numb += a\n",
    "                emit1_data.append(other_numb)\n",
    "                emit1_labels.append('other')\n",
    "\n",
    "                a, b = plt.pie(emit1_data, labels=emit1_labels, radius=2, colors=kcolors, labeldistance=0.8)\n",
    "                for bb in b:\n",
    "                    bb.set_horizontalalignment('center')\n",
    "                    bb.set_fontsize(12)\n",
    "                pltpath = '%s/%s/%s' %(path, corpus_name, mode)\n",
    "                if not os.path.exists(pltpath):\n",
    "                    os.makedirs(pltpath)\n",
    "                plt.savefig(pltpath+'/%s_%s.png' %(K, k), bbox_inches='tight')\n",
    "                plt.close()\n",
    "        pie_nodes(FIT_DATA)\n",
    "\n",
    "        def neato_function(K):\n",
    "            import networkx as nx\n",
    "            from networkx.drawing.nx_agraph import write_dot, to_agraph\n",
    "            import pygraphviz as pgv\n",
    "            G = nx.DiGraph()\n",
    "            labels =[x+1 for x in range(K)]\n",
    "            for x, y in zip(trans, labels):\n",
    "                for a, b in zip(x, labels):\n",
    "                    if a >= .01: #threshold*******\n",
    "                        G.add_edge(y, b, penwidth=a*8, weight=int(a*100))\n",
    "            edge_weights = []\n",
    "            edges = G.edges(data=True)\n",
    "#             print('edges:', edges)\n",
    "            for x in edges:\n",
    "                edge_weights.append(x[2]['penwidth'])\n",
    "            nodes = G.nodes()\n",
    "#             print('nodes:', nodes)\n",
    "            for x in range(len(nodes)):\n",
    "                G.node[nodes[x]]['shape'] = 'none'\n",
    "#                 G.node[nodes[x]]['image'] = '/home/daniel/Desktop/54.svg'\n",
    "                G.node[nodes[x]]['image'] = '%s/%s/%s/%s_%s.png' %(path, corpus_name, mode, K,x)\n",
    "                print('%s/%s/%s/%s_%s.svg' %(path, corpus_name, mode, K,x))\n",
    "                G.node[nodes[x]]['fontcolor'] = 'blue'\n",
    "                G.node[nodes[x]]['fontsize'] = 40\n",
    "            G = to_agraph(G)\n",
    "            # G=pgv.AGraph(ranksep=10)\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            print(G)\n",
    "#             G.draw('tryit.pdf', format='pdf', prog='dot')\n",
    "            G.draw('%s/%s_%s_%s.pdf' %(path, corpus_name, mode, K), format='pdf', prog='dot')\n",
    "        neato_function(K)\n",
    "        print('finished', corpus_name, mode, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alfabeto_chords_major = di.python_hmm(di.GetAll.all_alf, di.modal_major, 'chords')\n",
    "# alfabeto_chords_minor = di.python_hmm(di.GetAll.all_alf, di.modal_minor, 'chords')\n",
    "alfabeto_continuo_major = di.python_hmm(di.GetAll.all_alf, di.modal_major, 'continuo')\n",
    "alfabeto_continuo_minor = di.python_hmm(di.GetAll.all_alf, di.modal_minor, 'continuo')\n",
    "\n",
    "palestrina_major = di.python_hmm_corpus(di.palestrina_continuo, [(0, 0), (-1, 5)])\n",
    "palestrina_minor = di.python_hmm_corpus(di.palestrina_continuo, [(0, 9), (-1, 2)])\n",
    "# josquin_major = di.python_hmm_corpus(di.josquin_continuo, [(0, 0), (-1, 5)])\n",
    "\n",
    "# barbershop_major = di.python_hmm_corpus(di.barbershop_continuo, di.tonal_major)\n",
    "\n",
    "# masses = di.python_hmm_corpus(di.zma_continuo, [(0, 0), (-1, 5)])\n",
    "# motets = di.python_hmm_corpus(di.zmo_continuo, [(0, 0), (-1, 5)])\n",
    "# songs = di.python_hmm_corpus(di.zso_continuo, di.modal_major)\n",
    "\n",
    "\n",
    "bach_major = di.python_hmm_corpus(di.bach_continuo, di.tonal_major)\n",
    "bach_minor = di.python_hmm_corpus(di.bach_continuo, di.tonal_minor)\n",
    "# monteverdi_major = di.python_hmm_corpus(di.monteverdi_continuo, di.modal_major)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(masses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function_graph_maker(alfabeto_chords_major, 'alfabeto_chords', 'major', [11])\n",
    "# function_graph_maker(alfabeto_chords_minor, 'alfabeto_chords', 'minor', [11])\n",
    "# function_graph_maker(alfabeto_continuo_major, 'alfabeto_continuo', 'major', [3], '/home/daniel/Desktop/hmm')\n",
    "# function_graph_maker(alfabeto_continuo_minor, 'alfabeto_continuo', 'minor', [3], '/home/daniel/Desktop/hmm')\n",
    "\n",
    "# function_graph_maker(masses, 'masses', 'major', [11], '/home/daniel/Desktop/hmm')\n",
    "\n",
    "# function_graph_maker(alfabeto_continuo_minor, 'alfabeto_continuo', 'minor', 6)\n",
    "\n",
    "# function_graph_maker(palestrina_major, 'palestrina', 'major', [3], '/home/daniel/Desktop/hmm')\n",
    "# function_graph_maker(palestrina_minor, 'palestrina', 'minor', [3], '/home/daniel/Desktop/hmm')\n",
    "\n",
    "# function_graph_maker(masses, 'masses', 'major', [3], '/home/daniel/Desktop/hmm')\n",
    "# function_graph_maker(motets, 'motets', 'major', [3], '/home/daniel/Desktop/hmm')\n",
    "# function_graph_maker(songs, 'songs', 'major', [3], '/home/daniel/Desktop/hmm')\n",
    "\n",
    "\n",
    "# function_graph_maker(bach_major, 'bach', 'major', [3], '/home/daniel/Desktop/hmm')\n",
    "# function_graph_maker(bach_minor, 'bach', 'minor', [3], '/home/daniel/Desktop/hmm')\n",
    "# function_graph_maker(josquin_major, 'josquin', 'major', [3])\n",
    "# function_graph_maker(josquin_major, 'josquin', 'major', [6])\n",
    "# function_graph_maker(barbershop_major, 'barbershop', 'major', [2], 'try.pdf')\n",
    "# function_graph_maker(monteverdi_major, 'monteverdi', 'major', [2], 'home/daniel/Desktop/hmm')\n",
    "\n",
    "for f in range(2, 15):\n",
    "    function_graph_maker(alfabeto_continuo_major, 'alfabeto_continuo', 'major', [f], '/home/daniel/Desktop/hmm')\n",
    "    function_graph_maker(alfabeto_continuo_minor, 'alfabeto_continuo', 'minor', [f], '/home/daniel/Desktop/hmm')\n",
    "    function_graph_maker(palestrina_major, 'palestrina', 'major', [f], '/home/daniel/Desktop/hmm')\n",
    "    function_graph_maker(palestrina_minor, 'palestrina', 'minor', [f], '/home/daniel/Desktop/hmm')\n",
    "    function_graph_maker(bach_major, 'bach', 'major', [f], '/home/daniel/Desktop/hmm')\n",
    "    function_graph_maker(bach_minor, 'bach', 'minor', [f], '/home/daniel/Desktop/hmm')\n",
    "# for book in range(1,8):\n",
    "#     function_kaps = di.python_hmm([di.GetComposer.all_kaps[book-1]], di.modal_major, 'continuo')\n",
    "#     function_graph_maker(function_kaps, 'kaps%s' % book, 'major', [4])\n",
    "#     function_graph_maker(function_kaps, 'kaps%s' % book, 'major', [5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "for w in range(2, 15):\n",
    "    for x in range(500):\n",
    "        a = joblib.load('/home/daniel/Desktop/hmm/alfabeto_continuo/major/%s/%s.pkl' %(w,x))\n",
    "        all_scores.append(((w,x),a['fit'].monitor_.converged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in all_scores:\n",
    "    if x[-1] == False:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmmm = [[1],[3],[2],[11],[2],[1],[6],[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = joblib.load('/home/daniel/Desktop/hmm/alfabeto_continuo/major/3/0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a['fit'].monitor_.converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.path.exists('C://Users/Daniel/Desktop/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "di.function_mapper(di.GetAll.all_alf, di.modal_major, di.alfabeto_continuo_major, 'alfaeto continuo', '/home/daniel/Desktop/alf.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Connection file '~/.ipython/profile_default/security/ipcontroller-client.json' not found.\nYou have attempted to connect to an IPython Cluster but no Controller could be found.\nPlease double-check your configuration and ensure that a cluster is running.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a0ba16b706f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mipp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniel/anaconda3/lib/python3.5/site-packages/ipyparallel/client/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, url_file, profile, profile_dir, ipython_dir, context, debug, sshserver, sshkey, password, paramiko, timeout, cluster_id, **extra_args)\u001b[0m\n\u001b[1;32m    395\u001b[0m                         \u001b[0mno_file_msg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                     ])\n\u001b[0;32m--> 397\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0murl_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_file_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Connection file '~/.ipython/profile_default/security/ipcontroller-client.json' not found.\nYou have attempted to connect to an IPython Cluster but no Controller could be found.\nPlease double-check your configuration and ensure that a cluster is running."
     ]
    }
   ],
   "source": [
    "\"\"\"Parallel Processing\"\"\"\n",
    "\n",
    "import ipyparallel as ipp\n",
    "from sklearn.externals import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "rc = ipp.Client()\n",
    "\n",
    "print(rc.ids)\n",
    "dview = rc[:]\n",
    "# dview.execute(palestrina_major = di.python_hmm_corpus(di.palestrina_continuo, [(0, 0), (-1, 5)]))\n",
    "dview.execute(palestrina_minor = di.python_hmm_corpus(di.palestrina_continuo, [(0, 9), (-1, 2)]))\n",
    "dview.execute(bach_major = di.python_hmm_corpus(di.bach_continuo, di.tonal_major))\n",
    "dview.execute(bach_minor = di.python_hmm_corpus(di.bach_continuo, di.tonal_minor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def function_graph_parallel(dict_number):\n",
    "    parallel_dict = {}\n",
    "    thing_number = 0\n",
    "    corpus_dict = {0:{'name': 'palestrina', 'mode': 'major', 'corpus': palestrina_major}, \n",
    "                   1:{'name': 'palestrina', 'mode': 'minor', 'corpus': palestrina_minor}, \n",
    "                   2:{'name': 'bach', 'mode': 'major', 'corpus': bach_major}, \n",
    "                   3:{'name': 'bach', 'mode': 'minor', 'corpus': bach_minor}}\n",
    "    for x in range(len(corpus_dict)):\n",
    "        for k in range(2, 15):\n",
    "            parallel_dict[thing_number] = {'data':corpus_dict[x], 'K_range': [k]}\n",
    "            thing_number += 1\n",
    "    corpus_function = parallel_dict[dict_number]['data']['corpus']\n",
    "    corpus_name = parallel_dict[dict_number]['data']['name']\n",
    "    mode = parallel_dict[dict_number]['data']['mode']\n",
    "    path = '/home/daniel/Desktop/hmm'\n",
    "    \n",
    "    def function_graph_maker(corpus_function, corpus_name, mode, K_range, path):\n",
    "        X = corpus_function\n",
    "        for K in K_range:\n",
    "            if not os.path.exists('%s/%s_%s_%s.pkl' % (path, corpus_name, mode, K)):\n",
    "                Y = hmm.MultinomialHMM(n_components=K, verbose=True,n_iter=1000,tol=.001)\n",
    "                Y.n_features=len(X[2])\n",
    "                FIT_DATA = Y.fit(X[0], X[1])\n",
    "                TOKEN_NAMES=X[2]\n",
    "                pickleit = {'fit': FIT_DATA, 'tokens': TOKEN_NAMES}\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "                joblib.dump(pickleit, '%s/%s_%s_%s.pkl' %(path, corpus_name, mode, K), compress=9)\n",
    "\n",
    "            FIT_DATA = joblib.load('%s/%s_%s_%s.pkl' %(path, corpus_name, mode, K))\n",
    "            emiss = FIT_DATA['fit'].emissionprob_\n",
    "            tokens = FIT_DATA['tokens']\n",
    "            trans = FIT_DATA['fit'].transmat_\n",
    "\n",
    "            def pie_nodes(fit_data_dict):\n",
    "                emiss = fit_data_dict['fit'].emissionprob_\n",
    "                tokens = fit_data_dict['tokens']\n",
    "            #     K = len(emiss)\n",
    "                plt.close()\n",
    "                for k in range(K):\n",
    "                    plt.figure(figsize=(2,2), tight_layout=True)\n",
    "                    emit1_data = []\n",
    "                    emit1_labels = []\n",
    "                    plt.rcParams['font.size'] = 14.0\n",
    "                    plt.rcParams['font.family'] = 'serif'\n",
    "                    plt.axis('equal')\n",
    "                    # csfont = {'fontname':'Comic Sans MS'}\n",
    "                    kcolors = ['white']\n",
    "                    other_numb = 0\n",
    "                    for a, b in zip(emiss[k], tokens):\n",
    "                        if a >= .03:\n",
    "                            emit1_data.append(a)\n",
    "                            emit1_labels.append(b)\n",
    "                        else:\n",
    "                            other_numb += a\n",
    "                    emit1_data.append(other_numb)\n",
    "                    emit1_labels.append('other')\n",
    "\n",
    "                    a, b = plt.pie(emit1_data, labels=emit1_labels, radius=2, colors=kcolors, labeldistance=0.8)\n",
    "                    for bb in b:\n",
    "                        bb.set_horizontalalignment('center')\n",
    "                        bb.set_fontsize(12)\n",
    "                    pltpath = '%s/%s/%s' %(path, corpus_name, mode)\n",
    "                    if not os.path.exists(pltpath):\n",
    "                        os.makedirs(pltpath)\n",
    "                    plt.savefig(pltpath+'/%s_%s.png' %(K, k), bbox_inches='tight')\n",
    "                    plt.close()\n",
    "            pie_nodes(FIT_DATA)\n",
    "\n",
    "            def neato_function(K):\n",
    "                import networkx as nx\n",
    "                from networkx.drawing.nx_agraph import write_dot, to_agraph\n",
    "                import pygraphviz as pgv\n",
    "                G = nx.DiGraph()\n",
    "                labels =[x+1 for x in range(K)]\n",
    "                for x, y in zip(trans, labels):\n",
    "                    for a, b in zip(x, labels):\n",
    "                        if a >= .01: #threshold*******\n",
    "                            G.add_edge(y, b, penwidth=a*8, weight=int(a*100))\n",
    "                edge_weights = []\n",
    "                edges = G.edges(data=True)\n",
    "    #             print('edges:', edges)\n",
    "                for x in edges:\n",
    "                    edge_weights.append(x[2]['penwidth'])\n",
    "                nodes = G.nodes()\n",
    "    #             print('nodes:', nodes)\n",
    "                for x in range(len(nodes)):\n",
    "                    G.node[nodes[x]]['shape'] = 'none'\n",
    "    #                 G.node[nodes[x]]['image'] = '/home/daniel/Desktop/54.svg'\n",
    "                    G.node[nodes[x]]['image'] = '%s/%s/%s/%s_%s.png' %(path, corpus_name, mode, K,x)\n",
    "                    print('%s/%s/%s/%s_%s.svg' %(path, corpus_name, mode, K,x))\n",
    "                    G.node[nodes[x]]['fontcolor'] = 'blue'\n",
    "                    G.node[nodes[x]]['fontsize'] = 40\n",
    "                G = to_agraph(G)\n",
    "                # G=pgv.AGraph(ranksep=10)\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "                print(G)\n",
    "    #             G.draw('tryit.pdf', format='pdf', prog='dot')\n",
    "                G.draw('%s/%s_%s_%s.pdf' %(path, corpus_name, mode, K), format='pdf', prog='dot')\n",
    "            neato_function(K)\n",
    "            print('finished', corpus_name, mode, K)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
